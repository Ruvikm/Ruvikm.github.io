<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》 | Ruvikm</title><meta name="author" content="Ruvikm,ruvikm@126.com"><meta name="copyright" content="Ruvikm"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="前言记录一下复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》的过程，以免就调包感觉自己什么也没干。不建议一步一步跟着我的步骤做，这个是实况，建议跳着看看再参考着做 论文概况借助工具，大概对此篇的论文的认识如下 这篇文章探讨了使用脉冲神经网络（SNN）进行自然语言处理任务的可行性，以实现比深度神经网络更节能的效果。">
<meta property="og:type" content="article">
<meta property="og:title" content="复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》">
<meta property="og:url" content="https://ruvikm.gitee.io/2023/06/23/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E3%80%8ASPIKING%20CONVOLUTIONAL%20NEURAL%20NETWORKS%20FOR%20TEXT%20CLASSIFICATION%E3%80%8B/index.html">
<meta property="og:site_name" content="Ruvikm">
<meta property="og:description" content="前言记录一下复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》的过程，以免就调包感觉自己什么也没干。不建议一步一步跟着我的步骤做，这个是实况，建议跳着看看再参考着做 论文概况借助工具，大概对此篇的论文的认识如下 这篇文章探讨了使用脉冲神经网络（SNN）进行自然语言处理任务的可行性，以实现比深度神经网络更节能的效果。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/16/JkFykT.png">
<meta property="article:published_time" content="2023-06-23T11:14:38.000Z">
<meta property="article:modified_time" content="2023-07-14T03:13:49.189Z">
<meta property="article:author" content="Ruvikm">
<meta property="article:tag" content="Ruvikm">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/04/16/JkFykT.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ruvikm.gitee.io/2023/06/23/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E3%80%8ASPIKING%20CONVOLUTIONAL%20NEURAL%20NETWORKS%20FOR%20TEXT%20CLASSIFICATION%E3%80%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="9JkfNskqFG_GoNoENeuOURgnZ0spBRJTNd61jHEmT_Q"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "h7z0eb1l6d");</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-14 11:13:49'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><script src="/live2d-widget/autoload.js"></script><meta name="generator" content="Hexo 7.0.0-rc1"><link rel="alternate" href="/atom.xml" title="Ruvikm" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2020/04/16/JkFykT.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Ruvikm"><span class="site-name">Ruvikm</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-23T11:14:38.000Z" title="发表于 2023-06-23 19:14:38">2023-06-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-14T03:13:49.189Z" title="更新于 2023-07-14 11:13:49">2023-07-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">论文复现</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>35分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="复现论文《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>记录一下复现论文<a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=pgU3k7QXuz0">《SPIKING CONVOLUTIONAL NEURAL NETWORKS FOR TEXT CLASSIFICATION》</a>的过程，<del>以免就调包感觉自己什么也没干</del>。<strong>不建议一步一步跟着我的步骤做，这个是实况，建议跳着看看再参考着做</strong></p>
<h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>借助工具，大概对此篇的论文的认识如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这篇文章探讨了使用脉冲神经网络（SNN）进行自然语言处理任务的可行性，以实现比深度神经网络更节能的效果。虽然SNN已被证明在视觉任务中可产生具有竞争力的结果，但由于以脉冲形式表示单词和处理变长文本的困难，对于它们在自然语言处理（NLP）任务中的有效性的研究还很少。作者提出了一种“转换+微调”的两步法来训练SNN进行文本分类，并提出了一种编码预训练词嵌入为脉冲训练的有效方法，使SNN能够利用来自大量文本数据的词嵌入。实证结果表明，经过所提出的方法训练的SNN在能源消耗更少的情况下能够实现与其DNN同行竞争的结果，并且它们也更具对抗性。该研究是在英语和中文语言的文本分类任务中展示SNN有效性的首批研究之一，并突显了转换方法和微调阶段中的代用梯度作为该领域的一个关键贡献。</span><br></pre></td></tr></table></figure>
<p>在论文的末尾，找到作者<a target="_blank" rel="noopener" href="https://github.com/Lvchangze/snn">开源的代码</a>，并将其下载下来</p>
<hr>
<h2 id="弯路1"><a href="#弯路1" class="headerlink" title="弯路1"></a><strong>弯路1</strong></h2><p>然后用<code>Pycharm</code>打开刚开作者的项目，找到<code>md文档</code>，点击<code>Install Requirements</code>旁边的绿色箭头一键安装环境</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20200449.png" alt="屏幕截图 2023-06-23 200449"></p>
<p>经过一段时间，大部分都安装好了，但是有些还是出现了类似如下的报错</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20201023.png" alt="屏幕截图 2023-06-23 201023"></p>
<p>这时候需要分别查看<code>requirements.txt</code>和<code>textattack_r.txt</code>文件里，查看有哪些包没有装好</p>
<p>首先把<code>Pycharm</code>的环境切换到<code>snn</code></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20195956-1687522789851-6.png" alt="屏幕截图 2023-06-23 195956"></p>
<p>查看<code>requirements.txt</code>文件</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20201847.png" alt="屏幕截图 2023-06-23 201847"></p>
<p>纳尼？！为什么显示一个都没装，那么刚刚的东西都装哪了</p>
<p>重新检查了一下刚刚命令行的代码，发现了问题，在脚本里使用<code>conda activate</code>是不会生效的</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20202649.png" alt="屏幕截图 2023-06-23 202649"></p>
<p>按照上面的建议，修改一下切换环境的代码，然后将第一句注销了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">conda create -n snn python=3.7</span></span><br><span class="line">CALL activate snn</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line">pip install -r textattack_r.txt</span><br></pre></td></tr></table></figure>
<p>再次点击旁边的绿色小箭头！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20204422.png" alt="屏幕截图 2023-06-23 204422"></p>
<p>emmmmm他演我！看来还是自己老老实实用命令行吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20205049.png" alt="屏幕截图 2023-06-23 205049"></p>
<p>而且环境里的Python文件都有问题了！</p>
<p>……</p>
<p>……</p>
<p>重头开始吧</p>
<p>先把环境删了重新装一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda remove -n snn --all</span><br></pre></td></tr></table></figure>
<h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><p>重装环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n snn python=3.7</span><br><span class="line">conda activate snn</span><br></pre></td></tr></table></figure>
<p>然后Pycharm重新加载一下环境，使用命令行进入到项目的路径</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /d D:\code\SNN</span><br></pre></td></tr></table></figure>
<p>安装环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br><span class="line">pip install -r textattack_r.txt</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20210230.png" alt="屏幕截图 2023-06-23 210230"></p>
<p>走起！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20210429.png" alt="屏幕截图 2023-06-23 210429"></p>
<p>找不见文件？！检查了一下，发现是作者是文件名和代码里的名字对不上（少了一个<code>i</code>）</p>
<p>把其中一句改一下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -r requrements.txt</span><br></pre></td></tr></table></figure>
<p>再跑一次！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20210804.png" alt="屏幕截图 2023-06-23 210804"></p>
<p>很好，没有报错！再继续安装另一个文件里的包</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20211222.png" alt="屏幕截图 2023-06-23 211222"></p>
<p>根据提示，只有 <code>pycld2</code>这个包没有安装成功</p>
<p>重新单独装一下试试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install pycld2</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20211601.png" alt="屏幕截图 2023-06-23 211601"></p>
<p>还是报错，这次发现了原因，是缺少某个C++的库，点进去提供的<a target="_blank" rel="noopener" href="https://visualstudio.microsoft.com/visual-cpp-build-tools/">链接</a>进行下载</p>
<p>选择如下模块进行安装（建议装在除C盘外的盘，占用</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-23%20211947.png" alt="屏幕截图 2023-06-23 211947"></p>
<p>经过大概20多分钟，安装完毕，重启，然后再次安装那个包</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20081107.png" alt="屏幕截图 2023-06-24 081107"></p>
<p>啊嘞，还报错！</p>
<p>通过搜索，看到了一个解决方案。首先进去这个<a target="_blank" rel="noopener" href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#pycld2">网站</a>下载需要安装的包，由于当前环境是Python3.7的，所以下载如下的包</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20083511.png" alt="屏幕截图 2023-06-24 083511"></p>
<p>下载完成后，使用如下命令进行安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install .whl文件的绝对路径</span><br></pre></td></tr></table></figure>
<p>例如我的命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install G:\Download\Chrome\pycld2-0.41-cp37-cp37m-win_amd64.whl</span><br></pre></td></tr></table></figure>
<p>走起！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20083832.png" alt="屏幕截图 2023-06-24 083832"></p>
<p>nice，这下包就全部安装完毕了，可以试试能不能跑起来了</p>
<h2 id="下载数据库ChnSenti"><a href="#下载数据库ChnSenti" class="headerlink" title="下载数据库ChnSenti"></a>下载数据库<code>ChnSenti</code></h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20084301.png" alt="屏幕截图 2023-06-24 084301"></p>
<p>当我翻到最后时，发现居然要自己准备数据集！！！</p>
<p>让我翻一下论文康康他们用的什么数据集，发现他们中文数据集用的是<code>ChnSenti</code>和<code>Waimai</code>，我挑了一个<code>ChnSenti</code>数据集</p>
<p>网上搜索一下<code>ChnSenti</code>数据集的下载地址，找到一个github的<a target="_blank" rel="noopener" href="https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/ChnSentiCorp_htl_all/intro.ipynb">地址</a></p>
<p>将下载的<code>ChnSentiCorp_htl_all.csv</code>文件放在项目中（新建一个名为datasets的文件夹）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20090501.png" alt="屏幕截图 2023-06-24 090501"></p>
<p>然后应该就是找找从哪调用这个数据集，改一下路径什么的了</p>
<h2 id="安装环境DLC"><a href="#安装环境DLC" class="headerlink" title="安装环境DLC"></a>安装环境DLC</h2><p>ちょっと待って，好像还有包没有装完</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20090634.png" alt="屏幕截图 2023-06-24 090634"></p>
<p>鼠标右键一键安装一下（好像要一个什么插件，根据Pycharm的提示安装一下就行）</p>
<p>然后就可以<del>摸摸鱼</del>了</p>
<p>经过了一个多小时的等待，安装的差不多了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/image-20230624132216425.png" alt="image-20230624132216425"></p>
<p>把剩下的包再装一下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install bert-score==0.3.5</span><br><span class="line">pip install flair</span><br><span class="line">pip install pinyin==0.4.0</span><br><span class="line">pip install OpenHowNet</span><br></pre></td></tr></table></figure>
<p>安装完毕后，就会显示浅色的波浪线了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20155740.png" alt="屏幕截图 2023-06-24 155740"></p>
<p>接下来应该就是跑程序了，我需要跑的是一个中文数据集</p>
<p>根据作者的md文件</p>
<p><strong>Shift Pre-trained Word Embeddings to [0, 1]</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd data_preprocess</span><br><span class="line">python tensor_encoder.py</span><br><span class="line">python chinese_tensor_encoder.py</span><br></pre></td></tr></table></figure>
<p>找到<code>项目根目录\data_preprocess\chinese_tensor_encoder.py</code></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20162120.png" alt="屏幕截图 2023-06-24 162120"></p>
<p>这里应该需要把地址和数据集（也改成txt格式的）改一下</p>
<p>先换格式</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20162547.png" alt="屏幕截图 2023-06-24 162547"></p>
<p>然后改一下地址</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">datafile_path=<span class="string">&quot;../datasets/chnsenti_test.txt&quot;</span></span><br></pre></td></tr></table></figure>
<p>先跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20163436.png" alt="屏幕截图 2023-06-24 163436"></p>
<h2 id="重装numpy"><a href="#重装numpy" class="headerlink" title="重装numpy"></a>重装numpy</h2><p>大概意思应该是我<code>numpy</code>这个包有问题，康康自己是装的是什么版本的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure>
<p>然后<code>Ctrl+Shift+F</code>搜索一下<code>numpy</code>，发现我的版本是<code>1.21.6</code>，盲猜是不是有点高了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20163609.png" alt="屏幕截图 2023-06-24 163609"></p>
<p>根据之前的经验，可能是<code>TensorFlow</code>和<code>numpy</code>的版本不适配导致的</p>
<p>于是查了一下，果然不匹配，我的<code>TensorFlow</code>版本是<code>1.14.0</code></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20164441.png" alt="屏幕截图 2023-06-24 164441"></p>
<p>于是重装一下<code>numpy</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U numpy==1.16.0</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20164740.png" alt="屏幕截图 2023-06-24 164740"></p>
<p>然后跳出来一片红……<del>我的基金要是这样红该有多好</del></p>
<p>研究一下，装一下版本为<code>1.17.3</code>的就可以全解决，再试一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U numpy==1.17.3</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20165037.png" alt="屏幕截图 2023-06-24 165037"></p>
<p>还有一个问题，是<code>torchvision</code>不和<code>torch</code>版本不匹配，重新安装一下<code>torch</code>吧，（我记得他会自动卸载之前的版本）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cudatoolkit=11.3</span><br></pre></td></tr></table></figure>
<p>安装完以后，在试一次！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20180924.png" alt="屏幕截图 2023-06-24 180924"></p>
<p>又双叒叕报错了，这次应该是<code>pyarrow</code>这个包有问题，试试重装？</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U pyarrow</span><br></pre></td></tr></table></figure>
<p>再跑一次试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20181728.png" alt="屏幕截图 2023-06-24 181728"></p>
<p>好消息，刚才那个错是没有了。看前面几行，好像是<code>numpy</code>装了两个版本吗，查看一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20184534.png" alt="屏幕截图 2023-06-24 184534"></p>
<p>只有一个啊，是不是之前操作失误，把包全装在base环境里导致的</p>
<p>切换到<code>base</code>环境删除numpy（这个需要使用管理员运行<code>prompt</code>）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip uninstall numpy</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20185504.png" alt="屏幕截图 2023-06-24 185504"></p>
<p>再跑一次试试</p>
<p>好吧还是刚刚那个问题，要不这次直接物理删除试试<code>\doge</code>，找到他说的地方，删除其中一个文件</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20185819.png" alt="屏幕截图 2023-06-24 185819"></p>
<p>在跑一次康康有没有前面的报错了（删除要关闭Pycharm，否则会提示文件被占用）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20190048.png" alt="屏幕截图 2023-06-24 190048"></p>
<p>啊这，这是删除崩了吗，那就重装一下吧，把剩下的直接物理删除完</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20190201.png" alt="屏幕截图 2023-06-24 190201"></p>
<p>重新安装一下（复制一下上面的代码</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U numpy==1.17.3</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20190459.png" alt="屏幕截图 2023-06-24 190459"></p>
<p>怎么感觉自己越走越远了，试试他给我的建议</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install --force-reinstall --no-deps numpy==1.21.6</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20190740.png" alt="屏幕截图 2023-06-24 190740"></p>
<p>淦，还不行，等等，我可以从回收站恢复！还可以挽救。</p>
<p>恢复完毕后，再跑一下看看</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20190953.png" alt="屏幕截图 2023-06-24 190953"></p>
<p>又回到了这个熟悉的报错，那就先解决下面的问题吧，感觉是什么<code>xxhash</code>的包有问题</p>
<p>重新安装一下试试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U xxhash</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20191156.png" alt="屏幕截图 2023-06-24 191156"></p>
<p>看来刚刚一番折腾，还得把<code>numpy</code>这个包重装一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U numpy==1.17.3</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20191311.png" alt="屏幕截图 2023-06-24 191311"></p>
<p>啊？我康康能不能先卸载了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20191512.png" alt="屏幕截图 2023-06-24 191512"></p>
<p>也不太行，查了一下网上的强制升级试试？</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install numpy --ignore-installed numpy</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20191614.png" alt="屏幕截图 2023-06-24 191614"></p>
<p>nice，装好了，那再重装到<code>1.17.3</code>版本试试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U numpy==1.17.3</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20191712.png" alt="屏幕截图 2023-06-24 191712"></p>
<p>回来了，都回来了！跑一下试试</p>
<h2 id="解决报错OSError-WinError-126"><a href="#解决报错OSError-WinError-126" class="headerlink" title="解决报错OSError: [WinError 126]"></a>解决报错OSError: [WinError 126]</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20191846.png" alt="屏幕截图 2023-06-24 191846"></p>
<p>又换错了…但是前面的冲突居然没有了耶</p>
<p>查了一下网上这个错最好还是重装</p>
<p>那就试试重装<code>nltk</code>这个包吧</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip uninstall nltk</span><br><span class="line">pip install nltk</span><br></pre></td></tr></table></figure>
<p>再跑试试。好吧还是上面那个错。网上看了一个<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40243750/article/details/120123119">博客</a>的解决方法，打算试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20193137.png" alt="屏幕截图 2023-06-24 193137"></p>
<p>但是这个错我感觉还是<code>nltk</code>这个包的问题啊</p>
<p>查一下作者用的版本</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20193236.png" alt="屏幕截图 2023-06-24 193236"></p>
<p>这也太痛了，那么就查一下<code>nltk</code>关于<code>OSError: [WinError 126]</code>这个错的方向吧</p>
<p>果不其然搜到了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20193523.png" alt="屏幕截图 2023-06-24 193523"></p>
<p>照着上面的解决方案做一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20193720.png" alt="屏幕截图 2023-06-24 193720"></p>
<p>但是还是有戏的，安装完毕</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20193921.png" alt="屏幕截图 2023-06-24 193921"></p>
<p>再….跑一次试试吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-24%20194018.png" alt="屏幕截图 2023-06-24 194018"></p>
<p>？？？为什么。网上搜了一圈也没有很合适的，问问万能的chatGPT吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-26%20230624.png" alt="屏幕截图 2023-06-26 230624"></p>
<p>我盲猜可能是因为第三条，安装一下试试，由于找不见他说的<code>Microsoft Visual C++ Redistributable for Visual Studio</code>，我直接装了一个IDE，（这总可以包含了吧）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20180927.png" alt="屏幕截图 2023-06-27 180927"></p>
<p>跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20181140.png" alt="屏幕截图 2023-06-27 181140"></p>
<p>oh no！我不信了！B站找到了一个<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1AF411M7Jo/?vd_source=d703d44820358e50191fc790dd38d074">下载方式</a>，把文件下载下来如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20181620.png" alt="屏幕截图 2023-06-27 181620"></p>
<p>运行一下<code>.bat</code>文件试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20182021.png" alt="屏幕截图 2023-06-27 182021"></p>
<p>然后重启一下试试，然后跑一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20182610.png" alt="屏幕截图 2023-06-27 182610"></p>
<p>所以可能就不是少装C++库的问题吧，把<code>nltk</code>重装了试试吧</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip uninstall nltk</span><br><span class="line">pip install nltk</span><br></pre></td></tr></table></figure>
<p>用网上验证成功安装的方法检测一下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20190509.png" alt="屏幕截图 2023-06-27 190509"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20190547.png" alt="屏幕截图 2023-06-27 190547"></p>
<p>这应该是成功安装了，再跑试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20182823.png" alt="屏幕截图 2023-06-27 182823"></p>
<p>卡住了啊！难道是这个版本太新了？可是也不知道作者的版本是多少啊emm。全局搜一下康康能不能有什么线索</p>
<p>最后也没找到emm，问问chatGPT 4.0的试试吧……</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">出现这个错误的原因可能是nltk库所依赖的某些模块或动态链接库在你的系统中找不到。为了帮助你解决这个问题，请按照以下步骤操作：</span><br><span class="line"></span><br><span class="line">1. 首先，确保你已经安装了nltk库。在conda虚拟环境中，你可以运行以下命令来安装nltk：</span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">conda activate your_env_name</span><br><span class="line">conda install -c anaconda nltk</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">将`your_env_name`替换为你的conda虚拟环境名称。</span><br><span class="line"></span><br><span class="line">2. 请确保你的操作系统中安装了对应的Visual C++运行时库。对于不同版本的Python，需要相应版本的Visual C++运行时库。例如，对于Python 3.7，你应该安装[Microsoft Visual C++ 2015-2019 Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)。</span><br><span class="line"></span><br><span class="line">3. 如果问题仍未解决，请尝试升级nltk库：</span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">conda activate your_env_name</span><br><span class="line">conda update nltk</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">4. 如果问题仍然存在，可以尝试重装nltk库：</span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">conda activate your_env_name</span><br><span class="line">conda uninstall nltk</span><br><span class="line">conda install -c anaconda nltk</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">5. 如果以上方法都不能解决问题，请尝试在conda虚拟环境中安装`nltk`库的依赖项。例如，`numpy`可能是一个必要的依赖项。要安装它，请运行：</span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">conda activate your_env_name</span><br><span class="line">conda install numpy</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">希望上述步骤能帮助你解决问题。如果问题仍然存在，请提供更多详细信息，以便我们能够更好地帮助你。</span><br></pre></td></tr></table></figure>
<p>感觉完全没用呀，要不我试试把<code>x86</code>的<code>Microsoft Visual C++ 2015-2019 Redistributable</code>卸载了？有没有可能和<code>x64</code>版本的相互影响？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20184933.png" alt="屏幕截图 2023-06-27 184933"></p>
<p>卸载完后，在运行试试？</p>
<p>太离谱了，还是上面的错！又看了几个博客，好像意思是可能是依赖缺少的问题，他们推荐用<a target="_blank" rel="noopener" href="https://dependencywalker.com/">Dependency Walker</a>这个软件下一下组件</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20185446.png" alt="屏幕截图 2023-06-27 185446"></p>
<p>我下载的是这个，根据网上说明，只要找到<code>dll</code>或者<code>exe</code>文件就可以了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChWSWd.png" alt="屏幕截图 2023-06-27 191021"></p>
<p>但是！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20190817.png" alt="屏幕截图 2023-06-27 190817"></p>
<p>就离谱！<code>exe</code>文件也一样</p>
<p>仔细想了想，可能<code>nltk</code>这个库确实是没问题的，那么可能是他下面依赖的库不全的问题，继续查看报错的信息，看到最后一行</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20191447.png" alt="屏幕截图 2023-06-27 191447"></p>
<p>他最后要找的是<code>ctypes</code>这个库下的某个东西，结果没有找到，那可能出问题的是<code>ctypes</code>这个库？</p>
<p>安装一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install ctypes</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20192030.png" alt="屏幕截图 2023-06-27 192030"></p>
<p>打扰了，使用<code>conda</code>安装也装不了</p>
<p>又难道是<code>scipy</code>这个库，他说<code>scipy&gt;=1.4.1</code>，我的版本是<code>1.7.3</code>难道是太高了吗</p>
<p>试试重装一个<code>1.4.1</code>版本的</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -U scipy==1.4.1</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-27%20194333.png" alt="屏幕截图 2023-06-27 194333"></p>
<p>跑一下试试吧…</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/Ruvikm/pic/raw/master/img/image-20230627194555681.png" alt="image-20230627194555681"></p>
<p>woc？！这个错解决了吗？！ohhhhhhh</p>
<h2 id="弯路2"><a href="#弯路2" class="headerlink" title="弯路2"></a><strong>弯路2</strong></h2><hr>
<p>这个错感觉好说，配一下路径就行（理论上</p>
<p>好像是没有下载<code>word2vec</code>这个数据集，网上搜了一下，找到了好人发的<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1kTCQqft?_at_=1632703228320">度盘资源</a>，下载下来康康</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdt3Xq.png" alt="image-20230628114534236"></p>
<p>emmm怎么用呢，好像和程序里的目录不太一样</p>
<p>在论文里康康</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdRdeS.png" alt="79405c0f6bd9693beb7fdeafaf230a9"></p>
<p>我不会还要自己先用这个工具包先弄出点数据吧…</p>
<p>往下看md文档，好像下面就是训练数据了，先试试可以跳过预训练不</p>
<p>Train Tailored Models</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python main.py \</span><br><span class="line">--mode train </span><br><span class="line">--model_mode ann </span><br><span class="line">--model_type textcnn</span><br></pre></td></tr></table></figure>
<p>把这部分改成bash语言（转换用的chatGPT)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line">python main.py ^</span><br><span class="line">--mode train ^</span><br><span class="line">--model_mode ann ^</span><br><span class="line">--model_type textcnn</span><br></pre></td></tr></table></figure>
<p>然后新建一个.bat文件，把这段代码放进去跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWeYj.png" alt="image-20230628160203135"></p>
<p>走起</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWupn.png" alt="image-20230628160249712"></p>
<p>盲猜是因为在脚本里没有选择环境(之前的经验)，在脚本最前面加入这段代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">%切换到snn环境%</span><br><span class="line">CALL activate snn</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWJk4.png" alt="image-20230628160628632"></p>
<p>跑一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWUpR.png" alt="image-20230628160706883"></p>
<p>好像是又少什么包了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWwX6.png" alt="image-20230628160811533"></p>
<p>对比了一下，画红线的那两个包在代码里也没有啊，要不注释了试试吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWR1I.png" alt="image-20230628161111726"></p>
<p>再跑试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWWct.png" alt="image-20230628161142673"></p>
<p>看了一下，下面的代码还用到了，那就退回上一步，用<code>IDE</code>的建议试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdWOcq.png" alt="image-20230628161422730"></p>
<p>可恶，还报错</p>
<p>观察了一下刚刚转换完的脚本，他用的是<code>textcnn</code>这个模型，和报错的那两个没有关系</p>
<p>那就！把报错的全注释8！再运行一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdf6bT.png" alt="image-20230628162018807"></p>
<p>好像是路径的问题，怎么会有<code>lvchangze</code>这个文件夹</p>
<p>全局搜索一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdffPJ.png" alt="image-20230628162158756"></p>
<p>修改一下吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCdhjTU.png" alt="image-20230628163618882"></p>
<p>再试试吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/28/pCd49p9.png" alt="image-20230628163705575"></p>
<p>好消息是少了前面一坨红字了，网上查了一下这个错</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwYwD0.png" alt="image-20230629092442814"></p>
<p>看来可能还是路径的问题？修改一下刚刚改的路径试试</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">self.workspace = &#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN&#x27;</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwYDET.png" alt="image-20230629092733737"></p>
<p>跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwYg29.png" alt="image-20230629092837676"></p>
<p>行吧，还是那个错，但是我发现这个目录最后有一个<code>.log</code>文件，但是实习在那个目录里却没有</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwYqxA.png" alt="image-20230629092931037"></p>
<p>难道是因为创建不了这个文件的原因，所以导致读取不到吗（可能是不是权限的问题</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwYxVf.png" alt="image-20230629093039827"></p>
<p>加点权限试试，然后再跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwtP2j.png" alt="image-20230629093155829"></p>
<p>好吧，还是这个错。那试试用管理员开始bat文件？</p>
<p>可恶一闪而过了，加入点东西让他运行完停止</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">%使用<span class="built_in">read</span>命令达到类似bat中的pause命令效果%</span><br><span class="line"><span class="built_in">echo</span> 按任意键继续</span><br><span class="line"><span class="built_in">read</span> -n 1</span><br><span class="line"><span class="built_in">echo</span> 继续运行</span><br></pre></td></tr></table></figure>
<p>再运行试试，可恶也是一闪而过</p>
<p>这样吧，反正这玩意是日志，应该注释了不影响</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwtKG4.png" alt="image-20230629093706751"></p>
<p>给他注释了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwtMRJ.png" alt="image-20230629093746034"></p>
<p>这是数据集找不见了，全局搜索一下<code>data_path</code>的字段</p>
<p>根据脚本的字段设置，找到关于<code>ann</code>和<code>textcnn</code>相关的，修改一下路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--model_mode ann ^</span><br><span class="line">--model_type textcnn</span><br></pre></td></tr></table></figure>
<p>等等有一个更好的方法，可以让程序输出一下原本<code>data_path</code>里的字段，然后顺着这个字段改一下就行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;这里应该有数据集&quot;</span>+args.data_path)</span><br></pre></td></tr></table></figure>
<p>把上面这句加在这里</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwtrLt.png" alt="image-20230629094553351"></p>
<p>跑一下康康路径在哪</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwtWWQ.png" alt="屏幕截图 2023-06-29 094634"></p>
<p>bingo！把我刚找的数据集放在这个目录下试试吧，等等我找的应该不太行</p>
<p>他之前的文件夹是<code>sst2</code>，在论文里找一下这个数据集的下载方式吧</p>
<p>网上搜了一下<code>SST-2</code>是一个什么东西</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwNnmt.png" alt="image-20230629095830475"></p>
<p>这是他论文中提供的一个数据集的<a target="_blank" rel="noopener" href="https://www.cs.cornell.edu/people/pabo/movie-review-data/">下载地址</a>，搜了一圈，发现他是把积极和消极的评论数据集分开放了</p>
<p>发现我又从网上找到了一个<code>SST-2</code>的<a target="_blank" rel="noopener" href="https://dl.fbaipublicfiles.com/glue/data/SST-2.zip">下载地址</a>，下载下来后解压是这些文件</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwNXAf.png" alt="image-20230629101313283"></p>
<p>试试能不能套上去吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwa5yd.png" alt="image-20230629102623668"></p>
<p>跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCwaIOA.png" alt="image-20230629102827453"></p>
<p>啊好吧，可能是路径没改完，这样吧，直接在<code>main</code>文件里把传过来的地址改一下，把之前改的注销了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pCww0bR.png" alt="image-20230629103651187"></p>
<p>再跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/06/29/pC0SLUe.png" alt="image-20230629103825433"></p>
<p>阿哲，还可以下溢的吗</p>
<hr>
<h2 id="弯路3"><a href="#弯路3" class="headerlink" title="弯路3"></a>弯路3</h2><p>隔了好多天，网上看<a href="https://ruvikm.gitee.io/2023/07/04/word2vec%E5%B7%A5%E5%85%B7%E5%AE%9E%E6%88%98/">博客</a>用word2vec工具把预训练集弄出来了，这次试试吧</p>
<p>这次跑完生成了如下几个文件</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/05/pCydeAJ.png" alt="image-20230705154808654"></p>
<p>试试把预训练的代码改一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/05/pCyd0jf.png" alt="image-20230705155238466"></p>
<p>跑一下<code>data_preprocess/chinese_tensor_encoder.py</code>试试吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/05/pCydrDS.png" alt="image-20230705155346084"></p>
<p>有毒，那把第一个文件改成<code>wiki.zh.text.model.syn1neg</code>试试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vocab_path=<span class="string">&quot;../word2vec/wiki.zh.text.model.syn1neg&quot;</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/05/pCydfg0.png" alt="image-20230705155536477"></p>
<p>看来没有这个文件还是不太行啊</p>
<hr>
<h2 id="将预训练的词嵌入转移到-0-1"><a href="#将预训练的词嵌入转移到-0-1" class="headerlink" title="将预训练的词嵌入转移到 [0, 1]"></a>将预训练的词嵌入转移到 [0, 1]</h2><p>又过了一段时间，联系到了原作者，热心的作者给我发了这个文件！！！！</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">链接：https://pan.baidu.com/s/1eHcj8bvbQPAg76v7D<span class="built_in">_</span>Xs8A </span><br><span class="line">提取码：tvr8</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2Tnnx.png" alt="image-20230710124846593"></p>
<p>跑一跑试试吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2TJgA.png" alt="image-20230710125324489"></p>
<h2 id="解决编码问题"><a href="#解决编码问题" class="headerlink" title="解决编码问题"></a>解决编码问题</h2><p>好像是编码的问题？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2TwE8.png" alt="image-20230710125505872"></p>
<p>把里面的代码改改试试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(self.vocab_path, <span class="string">&quot;r&quot;</span>) //旧</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(self.vocab_path, <span class="string">&quot;r&quot;</span>,encoding=<span class="string">&#x27;utf8&#x27;</span>) //新</span><br></pre></td></tr></table></figure>
<p>再跑试试？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2TLb6.png" alt="image-20230710130032731"></p>
<p>这是在跑吗好像，先等会康康吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC27uxs.png" alt="image-20230710131123106"></p>
<p>看来可以跑，应该是刚刚没改干净，看来和<code>open</code>有关的都需要改</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(datafile_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:   //旧</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(datafile_path, <span class="string">&quot;r&quot;</span>,encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> f: //新</span><br></pre></td></tr></table></figure>
<p>再跑试试</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python chinese_tensor_encoder.py</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2jY0s.png" alt="image-20230710144910295"></p>
<p>还有错？！继续查查怎么改</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2jIje.png" alt="image-20230710145152994"></p>
<p>试试直接<code>ignore</code>了，不对，可能是我的数据集的问题</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pC2xpRK.png" alt="image-20230710150619368"></p>
<p>把<code>ChnSentiCorp_htl_all.csv</code>的内容直接复制到<code>chnsenti_test.txt</code>中，用<code>utf-8</code>就不会出现乱码了</p>
<p>再跑跑试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRp7k9.png" alt="image-20230710151333555"></p>
<p>6！把数据集直接改成<code>ChnSentiCorp_htl_all.csv</code>这个文件试试</p>
<p>emmm还是这个错，有仔细观察了一下，好像是<code>label</code>在第一个，句子在第二个，那感觉和代码里的就反过来了</p>
<p>之前的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentence = temp[<span class="number">0</span>].strip()</span><br><span class="line">label = <span class="built_in">int</span>(temp[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>改后:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentence = temp[<span class="number">1</span>].strip()</span><br><span class="line">label = <span class="built_in">int</span>(temp[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>再跑试试吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRKo7R.png" alt="image-20230710161042621"></p>
<p>emmm用<code>Pycharm</code>还不能直接运行，只能在命令行里运行</p>
<p>等等我知道我为什么pycharm运行不了了</p>
<p>之前迁移过一次环境从C盘到D盘，试了试这个<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44832009/article/details/129621060">博客的方法</a>，把这个问题解决了</p>
<p>调试了一下，发现要把数据集最开始的一行删了，感觉是那个导致的报错</p>
<p>再跑试试，发现还是那个错</p>
<p>我感觉可能是数据集变了处理数据的内容需要修改一下</p>
<p>康康chatGPT是怎么处理的吧：</p>
<p>可以使用Python中的字符串操作来提取这个句子并将它分别存放在label和sentence字段中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">text = &#x27;1,&quot;距离川沙公路较近,但是公交指示不对,如果是&quot;&quot;蔡陆线&quot;&quot;的话,会非常麻烦.建议用别的路线.房间较为简单.&quot;\n&#x27;</span><br><span class="line"></span><br><span class="line"># 提取label</span><br><span class="line">label = text.split(&#x27;,&#x27;)[0]</span><br><span class="line"></span><br><span class="line"># 提取sentence</span><br><span class="line">sentence = text.split(&#x27;,&#x27;)[1].strip()[1:-2]</span><br><span class="line"></span><br><span class="line">print(label)</span><br><span class="line">print(sentence)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">距离川沙公路较近,但是公交指示不对,如果是&quot;蔡陆线&quot;的话,会非常麻烦.建议用别的路线.房间较为简单.</span><br></pre></td></tr></table></figure>
<p>按照这个把代码改一改，原代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(datafile_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        temp = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        sentence = temp[<span class="number">0</span>].strip()</span><br><span class="line">        label = <span class="built_in">int</span>(temp[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># sentence = temp[1].strip()</span></span><br><span class="line">        <span class="comment"># label = int(temp[0])</span></span><br><span class="line">        sample_list.append((sentence, label))</span><br></pre></td></tr></table></figure>
<p>改完</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(datafile_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">       <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">           temp = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">           <span class="comment"># sentence = temp[0].strip()</span></span><br><span class="line">           <span class="comment"># label = int(temp[1])</span></span><br><span class="line">           sentence = temp[<span class="number">0</span>].split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>].strip()[<span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">           label = temp[<span class="number">0</span>].split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">           sample_list.append((sentence, label))</span><br></pre></td></tr></table></figure>
<p>跑跑试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRdGYF.png" alt="image-20230710184632963"></p>
<p>感觉有希望了耶，试试把报错那句的<code>utf8</code>去掉试试。再跑试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRdHpQ.png" alt="image-20230710185614613"></p>
<p>别报错别报错×114514</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRwAn1.png" alt="image-20230710190309371"></p>
<p>居然说我找不到文件，建个叫<code>senti</code>的文件夹试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRBsYT.png" alt="08f46c72ca112d14c2102a5e17a7406"></p>
<h2 id="训练定制模型"><a href="#训练定制模型" class="headerlink" title="训练定制模型"></a>训练定制模型</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRDd3D.png" alt="image-20230710194725452"></p>
<p>好像又是少文件，试试把刚刚跑出来的文件重命名为<code>train_u_3v_sst2_glove300d_sent_len25.tensor_dataset</code>试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRDrDA.png" alt="image-20230710195102925"></p>
<p>啊这，再把上面跑出来的文件复制一份改个名过去康康</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/10/pCRDRC8.png" alt="image-20230710195304235"></p>
<p>我怎么没看懂哪错了，从下往上看，找到最后项目代码报的那一行错</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(model.state_dict(), save_path)</span><br></pre></td></tr></table></figure>
<p>好像是我之前把日志那行代码注释了导致的</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pCfjlM8.png" alt="屏幕截图 2023-07-12 203749"></p>
<p>解除注释试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pCfj1sS.png" alt="image-20230712203926230"></p>
<p>又是文件读写的问题，好像日志文件就是创建不了，难道是系统权限的问题吗</p>
<h2 id="解决报错OSError-Errno-22-Invalid-argument"><a href="#解决报错OSError-Errno-22-Invalid-argument" class="headerlink" title="解决报错OSError:[Errno 22] Invalid argument"></a>解决报错OSError:[Errno 22] Invalid argument</h2><p>试试用管理员身份运行试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pCfvVyT.png" alt="image-20230712204810636"></p>
<p>看来不是权限的问题，突然网上看到了这个，我感觉很有道理耶</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pCfvmmF.png" alt="image-20230712204932116"></p>
<p>不能用冒号啊！！！！！！！！！！！！！！！！！！！！！！！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pChpwb8.png" alt="屏幕截图 2023-07-12 222221"></p>
<p>瞬间知道怎么改了</p>
<p>把这句改一下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">file_name = <span class="string">&quot;&#123;&#125;.log&quot;</span>.<span class="built_in">format</span>(time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, local_time))  //旧</span><br><span class="line"></span><br><span class="line">file_name = <span class="string">&quot;&#123;&#125;.log&quot;</span>.<span class="built_in">format</span>(time.strftime(<span class="string">&quot;%Y-%m-%d %H-%M-%S&quot;</span>, local_time))  //新</span><br></pre></td></tr></table></figure>
<p>跑一次试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pChpI54.png" alt="image-20230712222431492">怎么还有冒号</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pChpH2R.png" alt="image-20230712222534705"></p>
<p>把这里全局搜索到的都改一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pCh9CRA.png" alt="image-20230712222823863"></p>
<p>难道有戏？！</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/12/pCh9FMt.png" alt="image-20230712222935732"></p>
<p>对比一下作者的结果</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChW50f.png" alt="屏幕截图 2023-07-13 161415"></p>
<p>为什么作者的好高啊</p>
<h2 id="转换-归一化"><a href="#转换-归一化" class="headerlink" title="转换+归一化"></a>转换+归一化</h2><p>接下来就是把这句改成批处理的代码</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python main.py \</span><br><span class="line">--mode conversion</span><br><span class="line">--model_mode snn</span><br><span class="line">--model_type textcnn</span><br><span class="line">--conversion_mode normalize</span><br><span class="line">--conversion_normalize_type model_base or data_base</span><br></pre></td></tr></table></figure>
<p>转换完后，在前面加上切换环境的代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"></span><br><span class="line">%切换到snn环境%</span><br><span class="line">CALL activate snn</span><br><span class="line"></span><br><span class="line">python main.py ^</span><br><span class="line">--mode conversion ^</span><br><span class="line">--model_mode snn ^</span><br><span class="line">--model_type textcnn ^</span><br><span class="line">--conversion_mode normalize ^</span><br><span class="line">--conversion_normalize_type model_base or data_base</span><br></pre></td></tr></table></figure>
<p>跑一下试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChm1Vs.png" alt="image-20230713091029595"></p>
<p>这题我会！又是文件名不符合Windows的命名规则（<del>说人话就是不能出现<code>:</code></del>）</p>
<p>在全局搜一下<code>%H:%M:%S</code>关键字，但是我搜到的全改了啊</p>
<p>突然一看报的时间，咦？为什么是2022年的呢，可能是不是写死文件名了</p>
<p>顺着搜了一下</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChmRMD.png" alt="image-20230713091633520"></p>
<p>果然！！！把后面那部分去了试试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conversion_model_path = <span class="string">&quot;saved_models/2022-09-17 22:53:22.log--epoch4.pth&quot;</span>   //旧</span><br><span class="line">self.conversion_model_path = <span class="string">&quot;saved_models/&quot;</span>   //新</span><br></pre></td></tr></table></figure>
<p>再跑跑试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChnKW6.png" alt="image-20230713091926963"></p>
<p>为什么拒绝访问鸭。我懂了，应该是要加载某个文件，我试试加载一个文件试试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conversion_model_path = <span class="string">&quot;saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-07-12 22-29-13.log--epoch46.pth&quot;</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChn46U.png" alt="image-20230713093254555"></p>
<p>虽然但是，为什么精度还下降了一点emm。不过我的推理没错，这里果然是要加载一个文件，<del>跑起来就算成功</del></p>
<p>以下是作者的结果，好神秘只有<code>Conv SNN + MN</code>这一项和作者比较接近</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChfl3d.png" alt="image-20230713162351591"></p>
<h2 id="转换-微调"><a href="#转换-微调" class="headerlink" title="转换 + 微调"></a>转换 + 微调</h2><p>还是惯例，把下面的代码换成Windows下能运行的</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python main.py \</span><br><span class="line">--mode conversion</span><br><span class="line">--model_mode snn</span><br><span class="line">--model_type textcnn</span><br><span class="line">--conversion_mode tune</span><br></pre></td></tr></table></figure>
<p>换成.bat文件后，加上环境</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"></span><br><span class="line">%切换到snn环境%</span><br><span class="line">CALL activate snn</span><br><span class="line"></span><br><span class="line">python main.py ^</span><br><span class="line">--mode conversion ^</span><br><span class="line">--model_mode snn ^</span><br><span class="line">--model_type textcnn ^</span><br><span class="line">--conversion_mode tune</span><br></pre></td></tr></table></figure>
<p>运行试试</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChuNB4.png" alt="image-20230713094327585"></p>
<p>为什么不动鸭，再等等吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChuyjO.png" alt="image-20230713094837489"></p>
<p>速度好慢，一直挂着吧</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChMaf1.png" alt="image-20230713102720050"></p>
<p>半小时走了20%</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChURQH.png" alt="image-20230713112248591"></p>
<p>过了一小时，又走了20%多</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChdMEq.png" alt="image-20230713115158894"></p>
<p>又过了一小时，说起来这玩意占资源占的好多</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChd88U.png" alt="image-20230713115306126"></p>
<p>又过了一个多小时….</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pCh0yBd.png" alt="image-20230713125534432"></p>
<p>ohhhhhhhhhhhhhh终于跑完了</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChBubd.png" alt="屏幕截图 2023-07-13 131142"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChBnDH.png" alt="屏幕截图 2023-07-13 131125"></p>
<p>记录一下全部的输出</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">cmd.exe /c &quot;Conversion + Fine-tuning SNNs.bat&quot;</span><br><span class="line">Program args: SNNArgs(args<span class="built_in">_</span>for<span class="built_in">_</span>logging=[&#x27;model<span class="built_in">_</span>mode&#x27;, &#x27;mode&#x27;, &#x27;conversion<span class="built_in">_</span>mode&#x27;, &#x27;model<span class="built_in">_</span>type&#x27;, &#x27;dataset<span class="built_in">_</span>name&#x27;, &#x27;conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>type&#x27;, &#x27;label<span class="built_in">_</span>num&#x27;, &#x27;positive<span class="built_in">_</span>init<span class="built_in">_</span>rate&#x27;, &#x27;num<span class="built_in">_</span>steps&#x27;, &#x27;learning<span class="built_in">_</span>rate&#x27;], attack<span class="built_in">_</span>logging<span class="built_in">_</span>dir=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN<span class="keyword">\\</span>logs<span class="built_in">_</span>attack&#x27;, attack<span class="built_in">_</span>method=&#x27;textfooler&#x27;, attack<span class="built_in">_</span>model<span class="built_in">_</span>path=&#x27;saved<span class="built_in">_</span>models/best.pth&#x27;, attack<span class="built_in">_</span>numbers=1000, attack<span class="built_in">_</span>text<span class="built_in">_</span>path=&#x27;data/sst2/test.txt&#x27;, attack<span class="built_in">_</span>times=1, batch<span class="built_in">_</span>size=32, beta=1.0, bidirectional=&#x27;True&#x27;, bit=8, codebook<span class="built_in">_</span>type=&#x27;green&#x27;, conversion<span class="built_in">_</span>mode=&#x27;tune&#x27;, conversion<span class="built_in">_</span>model<span class="built_in">_</span>path=&#x27;saved<span class="built_in">_</span>models/model<span class="built_in">_</span>modeann-modetrain-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-sentence<span class="built_in">_</span>length25-dropout<span class="built_in">_</span>p0.5-weight<span class="built_in">_</span>decay0.0-batch<span class="built_in">_</span>size32-learning<span class="built_in">_</span>rate0.0001-label<span class="built_in">_</span>num2/2023-07-12 22-29-13.log--epoch46.pth&#x27;, conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>type=&#x27;model<span class="built_in">_</span>base&#x27;, data<span class="built_in">_</span>augment<span class="built_in">_</span>path=&#x27;data/sst2/train<span class="built_in">_</span>augment.txt&#x27;, data<span class="built_in">_</span>dir=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN<span class="keyword">\\</span>data<span class="keyword">\\</span>sst2&#x27;, data<span class="built_in">_</span>path=&#x27;data/sst2/train<span class="built_in">_</span>u<span class="built_in">_</span>3v<span class="built_in">_</span>sst2<span class="built_in">_</span>glove300d<span class="built_in">_</span>sent<span class="built_in">_</span>len25.tensor<span class="built_in">_</span>dataset&#x27;, dataset<span class="built_in">_</span>name=&#x27;sst2&#x27;, dead<span class="built_in">_</span>neuron<span class="built_in">_</span>checker=&#x27;False&#x27;, dev<span class="built_in">_</span>data<span class="built_in">_</span>path=&#x27;data/sst2/dev<span class="built_in">_</span>u<span class="built_in">_</span>3v<span class="built_in">_</span>sst2<span class="built_in">_</span>glove300d<span class="built_in">_</span>sent<span class="built_in">_</span>len25.tensor<span class="built_in">_</span>dataset&#x27;, device=device(type=&#x27;cuda&#x27;), distill<span class="built_in">_</span>batch=32, distill<span class="built_in">_</span>epoch=30, dpcnn<span class="built_in">_</span>block<span class="built_in">_</span>num=2, dpcnn<span class="built_in">_</span>step<span class="built_in">_</span>length=5, dropout<span class="built_in">_</span>p=0.5, encode=&#x27;rate&#x27;, ensemble=&#x27;False&#x27;, ensemble<span class="built_in">_</span>class=2, epochs=50, feature<span class="built_in">_</span>loss<span class="built_in">_</span>weight=10, filter<span class="built_in">_</span>num=100, filters=[3, 4, 5], hidden<span class="built_in">_</span>dim=300, hidden<span class="built_in">_</span>layer<span class="built_in">_</span>num=200, initial<span class="built_in">_</span>method=&#x27;zero&#x27;, label<span class="built_in">_</span>num=2, learning<span class="built_in">_</span>rate=0.0001, logging<span class="built_in">_</span>dir=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN<span class="keyword">\\</span>logs<span class="keyword">\\</span>model<span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001&#x27;, logging<span class="built_in">_</span>path=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN<span class="keyword">\\</span>logs<span class="keyword">\\</span>model<span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\\</span>2023-07-13 09-38-21.log&#x27;, logit<span class="built_in">_</span>loss<span class="built_in">_</span>weight=1.0, loss=&#x27;ce<span class="built_in">_</span>rate&#x27;, lstm<span class="built_in">_</span>fc1<span class="built_in">_</span>num=200, lstm<span class="built_in">_</span>hidden<span class="built_in">_</span>size=150, lstm<span class="built_in">_</span>layers<span class="built_in">_</span>num=1, max<span class="built_in">_</span>len=25, mode=&#x27;conversion&#x27;, model<span class="built_in">_</span>mode=&#x27;snn&#x27;, model<span class="built_in">_</span>type=&#x27;textcnn&#x27;, modify<span class="built_in">_</span>ratio=0.1, neighbour<span class="built_in">_</span>vocab<span class="built_in">_</span>size=15, num<span class="built_in">_</span>steps=50, optimizer<span class="built_in">_</span>name=&#x27;Adamw&#x27;, positive<span class="built_in">_</span>init<span class="built_in">_</span>rate=0.55, pretrain<span class="built_in">_</span>embedding<span class="built_in">_</span>name=&#x27;glove&#x27;, saving<span class="built_in">_</span>dir=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN<span class="keyword">\\</span>saved<span class="built_in">_</span>models<span class="keyword">\\</span>model<span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001&#x27;, seed=42, sentence<span class="built_in">_</span>length=25, sentence<span class="built_in">_</span>similarity=0.8, student<span class="built_in">_</span>model<span class="built_in">_</span>name=&#x27;dpcnn&#x27;, surrogate=&#x27;fast<span class="built_in">_</span>sigmoid&#x27;, teacher<span class="built_in">_</span>model<span class="built_in">_</span>path=&#x27;saved<span class="built_in">_</span>models/bert-base-uncased<span class="built_in">_</span>2022-09-14 18:27:35<span class="built_in">_</span>epoch0<span class="built_in">_</span>0.9335529928610653&#x27;, test<span class="built_in">_</span>data<span class="built_in">_</span>path=&#x27;data/sst2/test<span class="built_in">_</span>u<span class="built_in">_</span>3v<span class="built_in">_</span>sst2<span class="built_in">_</span>glove300d<span class="built_in">_</span>sent<span class="built_in">_</span>len25.tensor<span class="built_in">_</span>dataset&#x27;, threshold=1.0, use<span class="built_in">_</span>codebook=&#x27;False&#x27;, use<span class="built_in">_</span>seed=&#x27;False&#x27;, vocab<span class="built_in">_</span>path=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN<span class="keyword">\\</span>data/glove.6B.300d.txt&#x27;, weight<span class="built_in">_</span>decay=0.0, workspace=&#x27;D:<span class="keyword">\\</span>code<span class="keyword">\\</span>SNN&#x27;)</span><br><span class="line">Build model...</span><br><span class="line">SNN<span class="built_in">_</span>TextCNN(</span><br><span class="line">  (convs<span class="built_in">_</span>1): ModuleList(</span><br><span class="line">    (0): Conv2d(1, 100, kernel<span class="built_in">_</span>size=(3, 300), stride=(1, 1))</span><br><span class="line">    (1): Conv2d(1, 100, kernel<span class="built_in">_</span>size=(4, 300), stride=(1, 1))</span><br><span class="line">    (2): Conv2d(1, 100, kernel<span class="built_in">_</span>size=(5, 300), stride=(1, 1))</span><br><span class="line">  )</span><br><span class="line">  (middle<span class="built_in">_</span>lifs): ModuleList(</span><br><span class="line">    (0): Leaky()</span><br><span class="line">    (1): Leaky()</span><br><span class="line">    (2): Leaky()</span><br><span class="line">  )</span><br><span class="line">  (avgpool<span class="built_in">_</span>1): ModuleList(</span><br><span class="line">    (0): AvgPool2d(kernel<span class="built_in">_</span>size=(23, 1), stride=(23, 1), padding=0)</span><br><span class="line">    (1): AvgPool2d(kernel<span class="built_in">_</span>size=(22, 1), stride=(22, 1), padding=0)</span><br><span class="line">    (2): AvgPool2d(kernel<span class="built_in">_</span>size=(21, 1), stride=(21, 1), padding=0)</span><br><span class="line">  )</span><br><span class="line">  (lif1): Leaky()</span><br><span class="line">  (fc<span class="built_in">_</span>1): Linear(in<span class="built_in">_</span>features=300, out<span class="built_in">_</span>features=2, bias=True)</span><br><span class="line">  (lif2): Leaky()</span><br><span class="line">)</span><br><span class="line">Build dataset...</span><br><span class="line">Build dataset...</span><br><span class="line">Build rated<span class="built_in">_</span>dataset...</span><br><span class="line">Build dataloader...</span><br><span class="line">Build rated<span class="built_in">_</span>dataset...</span><br><span class="line">Build dataloader...</span><br><span class="line">Test acc of conversioned textcnn is: 0.7939737316507854</span><br><span class="line">Build Optimizer...</span><br><span class="line">Training Begin</span><br><span class="line"> 56<span class="comment">%|█████▌    | 28/50 [2:00:10&lt;1:38:16, 268.02s/it]Dead_neuron_rate in epoch 0: 0.15.</span></span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 0: 0.0.</span><br><span class="line">Training epoch 0, avg<span class="built_in">_</span>loss: tensor([0.5627], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 0 is: 0.7807107906258048</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 09-44-12.log--epoch0.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 1: 0.15333333333333332.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 1: 0.0.</span><br><span class="line">Training epoch 1, avg<span class="built_in">_</span>loss: tensor([0.5601], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 1 is: 0.7866340458408447</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 09-47-44.log--epoch1.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 2: 0.15.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 2: 0.0.</span><br><span class="line">Training epoch 2, avg<span class="built_in">_</span>loss: tensor([0.5585], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 2 is: 0.7778779294360031</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 3: 0.15333333333333332.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 3: 0.0.</span><br><span class="line">Training epoch 3, avg<span class="built_in">_</span>loss: tensor([0.5592], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 3 is: 0.7863765130054082</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 4: 0.12333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 4: 0.0.</span><br><span class="line">Training epoch 4, avg<span class="built_in">_</span>loss: tensor([0.5588], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 4 is: 0.7892093741952099</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 09-59-33.log--epoch4.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 5: 0.16333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 5: 0.0.</span><br><span class="line">Training epoch 5, avg<span class="built_in">_</span>loss: tensor([0.5589], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 5 is: 0.7898532062838012</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 10-03-51.log--epoch5.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 6: 0.15.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 6: 0.0.</span><br><span class="line">Training epoch 6, avg<span class="built_in">_</span>loss: tensor([0.5583], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 6 is: 0.7944887973216586</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 10-08-05.log--epoch6.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 7: 0.15333333333333332.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 7: 0.0.</span><br><span class="line">Training epoch 7, avg<span class="built_in">_</span>loss: tensor([0.5564], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 7 is: 0.7647437548287407</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 8: 0.13333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 8: 0.0.</span><br><span class="line">Training epoch 8, avg<span class="built_in">_</span>loss: tensor([0.5547], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 8 is: 0.773886170486737</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 9: 0.15.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 9: 0.0.</span><br><span class="line">Training epoch 9, avg<span class="built_in">_</span>loss: tensor([0.5537], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 9 is: 0.7920422353850116</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 10: 0.15666666666666668.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 10: 0.0.</span><br><span class="line">Training epoch 10, avg<span class="built_in">_</span>loss: tensor([0.5517], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 10 is: 0.7962915271697142</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 10-25-53.log--epoch10.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 11: 0.15.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 11: 0.0.</span><br><span class="line">Training epoch 11, avg<span class="built_in">_</span>loss: tensor([0.5532], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 11 is: 0.7890806077774917</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 12: 0.14333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 12: 0.0.</span><br><span class="line">Training epoch 12, avg<span class="built_in">_</span>loss: tensor([0.5551], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 12 is: 0.7742724697398918</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 13: 0.15.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 13: 0.0.</span><br><span class="line">Training epoch 13, avg<span class="built_in">_</span>loss: tensor([0.5559], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 13 is: 0.801184651043008</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 10-38-37.log--epoch13.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 14: 0.13666666666666666.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 14: 0.0.</span><br><span class="line">Training epoch 14, avg<span class="built_in">_</span>loss: tensor([0.5492], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 14 is: 0.7755601339170745</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 15: 0.14666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 15: 0.0.</span><br><span class="line">Training epoch 15, avg<span class="built_in">_</span>loss: tensor([0.5500], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 15 is: 0.8000257532835436</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 16: 0.14.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 16: 0.0.</span><br><span class="line">Training epoch 16, avg<span class="built_in">_</span>loss: tensor([0.5511], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 16 is: 0.798738089106361</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 17: 0.14333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 17: 0.0.</span><br><span class="line">Training epoch 17, avg<span class="built_in">_</span>loss: tensor([0.5511], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 17 is: 0.800154519701262</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 18: 0.13666666666666666.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 18: 0.0.</span><br><span class="line">Training epoch 18, avg<span class="built_in">_</span>loss: tensor([0.5511], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 18 is: 0.7955189286634046</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 19: 0.14333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 19: 0.0.</span><br><span class="line">Training epoch 19, avg<span class="built_in">_</span>loss: tensor([0.5499], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 19 is: 0.7998969868658254</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 20: 0.14.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 20: 0.0.</span><br><span class="line">Training epoch 20, avg<span class="built_in">_</span>loss: tensor([0.5454], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 20 is: 0.7839299510687613</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 21: 0.14666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 21: 0.0.</span><br><span class="line">Training epoch 21, avg<span class="built_in">_</span>loss: tensor([0.5480], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 21 is: 0.7948750965748133</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 22: 0.14333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 22: 0.0.</span><br><span class="line">Training epoch 22, avg<span class="built_in">_</span>loss: tensor([0.5478], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 22 is: 0.8050476435745557</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 11-20-25.log--epoch22.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 23: 0.13.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 23: 0.0.</span><br><span class="line">Training epoch 23, avg<span class="built_in">_</span>loss: tensor([0.5459], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 23 is: 0.8016997167138811</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 24: 0.13.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 24: 0.0.</span><br><span class="line">Training epoch 24, avg<span class="built_in">_</span>loss: tensor([0.5517], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 24 is: 0.8019572495493176</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 25: 0.14333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 25: 0.0.</span><br><span class="line">Training epoch 25, avg<span class="built_in">_</span>loss: tensor([0.5518], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 25 is: 0.8047901107391192</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 26: 0.14333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 26: 0.0.</span><br><span class="line">Training epoch 26, avg<span class="built_in">_</span>loss: tensor([0.5454], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 26 is: 0.8023435488024723</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 27: 0.13666666666666666.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 27: 0.0.</span><br><span class="line">Training epoch 27, avg<span class="built_in">_</span>loss: tensor([0.5489], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">100<span class="comment">%|██████████| 50/50 [3:27:59&lt;00:00, 249.58s/it]</span></span><br><span class="line"></span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 28: 0.13.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 28: 0.0.</span><br><span class="line">Training epoch 28, avg<span class="built_in">_</span>loss: tensor([0.5489], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 28 is: 0.7604944630440381</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 29: 0.12.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 29: 0.0.</span><br><span class="line">Training epoch 29, avg<span class="built_in">_</span>loss: tensor([0.5444], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 29 is: 0.798738089106361</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 30: 0.12333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 30: 0.0.</span><br><span class="line">Training epoch 30, avg<span class="built_in">_</span>loss: tensor([0.5491], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 30 is: 0.7631985578161216</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 31: 0.12333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 31: 0.0.</span><br><span class="line">Training epoch 31, avg<span class="built_in">_</span>loss: tensor([0.5452], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 31 is: 0.7772340973474118</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 32: 0.11.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 32: 0.0.</span><br><span class="line">Training epoch 32, avg<span class="built_in">_</span>loss: tensor([0.5444], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 32 is: 0.8040175122328097</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 33: 0.11666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 33: 0.0.</span><br><span class="line">Training epoch 33, avg<span class="built_in">_</span>loss: tensor([0.5444], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 33 is: 0.8032449137265001</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 34: 0.11333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 34: 0.0.</span><br><span class="line">Training epoch 34, avg<span class="built_in">_</span>loss: tensor([0.5453], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 34 is: 0.7830285861447335</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 35: 0.11.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 35: 0.0.</span><br><span class="line">Training epoch 35, avg<span class="built_in">_</span>loss: tensor([0.5422], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 35 is: 0.7910121040432655</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 36: 0.11666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 36: 0.0.</span><br><span class="line">Training epoch 36, avg<span class="built_in">_</span>loss: tensor([0.5444], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 36 is: 0.8082668040175123</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 12-15-12.log--epoch36.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 37: 0.11.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 37: 0.0.</span><br><span class="line">Training epoch 37, avg<span class="built_in">_</span>loss: tensor([0.5459], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 37 is: 0.8078805047643575</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 38: 0.11333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 38: 0.0.</span><br><span class="line">Training epoch 38, avg<span class="built_in">_</span>loss: tensor([0.5459], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 38 is: 0.7796806592840587</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 39: 0.10666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 39: 0.0.</span><br><span class="line">Training epoch 39, avg<span class="built_in">_</span>loss: tensor([0.5416], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 39 is: 0.805176409992274</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 40: 0.10333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 40: 0.0.</span><br><span class="line">Training epoch 40, avg<span class="built_in">_</span>loss: tensor([0.5448], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 40 is: 0.8096832346124131</span><br><span class="line">D:<span class="keyword">\code</span><span class="keyword">\SNN</span><span class="keyword">\saved</span><span class="built_in">_</span>models<span class="keyword">\model</span><span class="built_in">_</span>modesnn-modeconversion-conversion<span class="built_in">_</span>modetune-model<span class="built_in">_</span>typetextcnn-dataset<span class="built_in">_</span>namesst2-conversion<span class="built_in">_</span>normalize<span class="built_in">_</span>typemodel<span class="built_in">_</span>base-label<span class="built_in">_</span>num2-positive<span class="built_in">_</span>init<span class="built_in">_</span>rate0.55-num<span class="built_in">_</span>steps50-learning<span class="built_in">_</span>rate0.0001<span class="keyword">\2</span>023-07-13 12-32-03.log--epoch40.pth</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 41: 0.09333333333333334.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 41: 0.0.</span><br><span class="line">Training epoch 41, avg<span class="built_in">_</span>loss: tensor([0.5424], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 41 is: 0.7995106876126706</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 42: 0.09.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 42: 0.0.</span><br><span class="line">Training epoch 42, avg<span class="built_in">_</span>loss: tensor([0.5402], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 42 is: 0.8072366726757662</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 43: 0.09666666666666666.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 43: 0.0.</span><br><span class="line">Training epoch 43, avg<span class="built_in">_</span>loss: tensor([0.5383], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 43 is: 0.8074942055112027</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 44: 0.09.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 44: 0.0.</span><br><span class="line">Training epoch 44, avg<span class="built_in">_</span>loss: tensor([0.5393], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 44 is: 0.8074942055112027</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 45: 0.08333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 45: 0.0.</span><br><span class="line">Training epoch 45, avg<span class="built_in">_</span>loss: tensor([0.5374], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 45 is: 0.7249549317537987</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 46: 0.08666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 46: 0.0.</span><br><span class="line">Training epoch 46, avg<span class="built_in">_</span>loss: tensor([0.5392], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 46 is: 0.8002832861189801</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 47: 0.08333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 47: 0.0.</span><br><span class="line">Training epoch 47, avg<span class="built_in">_</span>loss: tensor([0.5377], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 47 is: 0.8028586144733454</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 48: 0.08666666666666667.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 48: 0.0.</span><br><span class="line">Training epoch 48, avg<span class="built_in">_</span>loss: tensor([0.5361], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 48 is: 0.8007983517898533</span><br><span class="line">Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 49: 0.08333333333333333.</span><br><span class="line">Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate in epoch 49: 0.0.</span><br><span class="line">Training epoch 49, avg<span class="built_in">_</span>loss: tensor([0.5375], device=&#x27;cuda:0&#x27;, grad<span class="built_in">_</span>fn=&lt;DivBackward0&gt;).</span><br><span class="line">Test acc in epoch 49 is: 0.8078805047643575</span><br><span class="line">Mean Dead<span class="built_in">_</span>neuron<span class="built_in">_</span>rate: 0.1266</span><br><span class="line">Mean Too<span class="built_in">_</span>Activate<span class="built_in">_</span>neuron<span class="built_in">_</span>rate: 0.0</span><br><span class="line">Best Test Acc: 0.8096832346124131</span><br><span class="line"></span><br><span class="line">进程已结束,退出代码0</span><br></pre></td></tr></table></figure>
<p>作者的结果如下，比作者的低一点</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2023/07/13/pChfl3d.png" alt="image-20230713162351591"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>历时20多天，终于把这个论文复现出来了。</p>
<p><strong>再次感谢<a target="_blank" rel="noopener" href="https://github.com/Lvchangze">作者</a>，提供了数据集！！！</strong></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ruvikm.gitee.io">Ruvikm</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ruvikm.gitee.io/2023/06/23/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E3%80%8ASPIKING%20CONVOLUTIONAL%20NEURAL%20NETWORKS%20FOR%20TEXT%20CLASSIFICATION%E3%80%8B/">https://ruvikm.gitee.io/2023/06/23/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87%E3%80%8ASPIKING%20CONVOLUTIONAL%20NEURAL%20NETWORKS%20FOR%20TEXT%20CLASSIFICATION%E3%80%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ruvikm.gitee.io" target="_blank">Ruvikm</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://s1.ax1x.com/2020/04/16/JkFykT.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/24/%E5%A4%8D%E7%8E%B0%E9%A1%B9%E7%9B%AE%E3%80%8AGAT-BiLSTM-CRF%E3%80%8B/" title="跑通项目《GAT-BiLSTM-CRF》"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">跑通项目《GAT-BiLSTM-CRF》</div></div></a></div><div class="next-post pull-right"><a href="/2023/06/08/%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87ChineseBERT/" title="复现论文ChineseBERT(ONTONOTES数据集)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">复现论文ChineseBERT(ONTONOTES数据集)</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.ax1x.com/2020/04/16/JkFykT.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Ruvikm</div><div class="author-info__description">Today's accomplishments were yesterday's impossibilities</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Ruvikm"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客鸭~</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E6%A6%82%E5%86%B5"><span class="toc-number">2.</span> <span class="toc-text">论文概况</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%AF%E8%B7%AF1"><span class="toc-number">3.</span> <span class="toc-text">弯路1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83"><span class="toc-number">4.</span> <span class="toc-text">安装环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%BA%93ChnSenti"><span class="toc-number">5.</span> <span class="toc-text">下载数据库ChnSenti</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83DLC"><span class="toc-number">6.</span> <span class="toc-text">安装环境DLC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E8%A3%85numpy"><span class="toc-number">7.</span> <span class="toc-text">重装numpy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8A%A5%E9%94%99OSError-WinError-126"><span class="toc-number">8.</span> <span class="toc-text">解决报错OSError: [WinError 126]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%AF%E8%B7%AF2"><span class="toc-number">9.</span> <span class="toc-text">弯路2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%AF%E8%B7%AF3"><span class="toc-number">10.</span> <span class="toc-text">弯路3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E8%AF%8D%E5%B5%8C%E5%85%A5%E8%BD%AC%E7%A7%BB%E5%88%B0-0-1"><span class="toc-number">11.</span> <span class="toc-text">将预训练的词嵌入转移到 [0, 1]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98"><span class="toc-number">12.</span> <span class="toc-text">解决编码问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%AE%9A%E5%88%B6%E6%A8%A1%E5%9E%8B"><span class="toc-number">13.</span> <span class="toc-text">训练定制模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8A%A5%E9%94%99OSError-Errno-22-Invalid-argument"><span class="toc-number">14.</span> <span class="toc-text">解决报错OSError:[Errno 22] Invalid argument</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2-%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">15.</span> <span class="toc-text">转换+归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2-%E5%BE%AE%E8%B0%83"><span class="toc-number">16.</span> <span class="toc-text">转换 + 微调</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">17.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/12/%E4%BD%BF%E7%94%A8%E8%93%9D%E7%89%99%E5%A4%96%E8%AE%BE%E5%8D%B4%E4%B8%8D%E5%B0%8F%E5%BF%83%E6%8A%8A%E5%8F%B0%E5%BC%8F%E6%9C%BA%E7%94%B5%E8%84%91%E8%93%9D%E7%89%99%E5%85%B3%E4%BA%86/" title="使用蓝牙外设却不小心把台式机电脑蓝牙关了">使用蓝牙外设却不小心把台式机电脑蓝牙关了</a><time datetime="2023-08-12T09:43:40.000Z" title="发表于 2023-08-12 17:43:40">2023-08-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/12/%E6%8B%BC%E6%A8%A1%E5%9E%8B%E5%B0%9D%E8%AF%95/" title="拼模型尝试">拼模型尝试</a><time datetime="2023-08-12T02:40:48.000Z" title="发表于 2023-08-12 10:40:48">2023-08-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/21/%E5%AE%89%E8%A3%85PaddlePaddle/" title="安装PaddlePaddle">安装PaddlePaddle</a><time datetime="2023-07-21T02:23:04.000Z" title="发表于 2023-07-21 10:23:04">2023-07-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/15/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2chatGPT/" title="本地部署chatGPT">本地部署chatGPT</a><time datetime="2023-07-15T01:13:30.000Z" title="发表于 2023-07-15 09:13:30">2023-07-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/12/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98OSError%20%5BErrno%2022%5D%20Invalid%20argument/" title="OSError [Errno 22] Invalid argument(已解决)">OSError [Errno 22] Invalid argument(已解决)</a><time datetime="2023-07-12T14:31:56.000Z" title="发表于 2023-07-12 22:31:56">2023-07-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Ruvikm</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">去把这个不完美的世界，变成你所期望的样子吧！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>